<?xml version="1.0" encoding="utf-8"?>
<odoo>
    <!-- Vanna Configuration Form View -->
    <record id="view_vanna_config_form" model="ir.ui.view">
        <field name="name">vanna.config.form</field>
        <field name="model">vanna.config</field>
        <field name="arch" type="xml">
            <form string="Vanna AI Configuration">
                <header>
                    <button name="action_download_and_setup"
                            string="Download &amp; Start Server"
                            type="object"
                            class="oe_highlight"
                            invisible="llm_status == 'running'"/>
                    <button name="action_stop_server"
                            string="Stop Server"
                            type="object"
                            invisible="llm_status != 'running'"/>
                    <button name="action_test_connection"
                            string="Test Connection"
                            type="object"
                            invisible="llm_status != 'running'"/>
                    <field name="llm_status" widget="statusbar"
                           statusbar_visible="not_installed,downloading,installing,running"/>
                </header>
                <sheet>
                    <div class="oe_title">
                        <h1>
                            <field name="llm_backend" placeholder="Select LLM Backend"/>
                        </h1>
                    </div>
                    <group>
                        <group string="LLM Configuration">
                            <field name="llm_backend"/>
                            <field name="custom_model_url"
                                   invisible="llm_backend != 'custom'"
                                   placeholder="https://huggingface.co/...model.gguf"/>
                            <field name="llm_port"/>
                        </group>
                        <group string="Status">
                            <field name="llm_status"/>
                            <field name="vanna_trained"/>
                            <field name="server_path" readonly="1"/>
                            <field name="model_path" readonly="1"/>
                        </group>
                    </group>
                    <group string="Error Log" invisible="not error_message">
                        <field name="error_message" readonly="1" nolabel="1"/>
                    </group>
                    <notebook>
                        <page string="Setup Instructions">
                            <group>
                                <div class="alert alert-info" role="alert">
                                    <h4>Setup Steps:</h4>
                                    <ol>
                                        <li>Select your preferred LLM backend</li>
                                        <li>For custom models, provide the GGUF model URL</li>
                                        <li>Click "Download &amp; Start Server" button</li>
                                        <li>Wait for the status to change to "Running"</li>
                                        <li>The chatbot widget will be available in all views</li>
                                    </ol>
                                    <h4>Requirements:</h4>
                                    <ul>
                                        <li>Git must be installed</li>
                                        <li>C++ compiler (gcc/g++)</li>
                                        <li>Python packages: vanna, requests</li>
                                        <li>Sufficient disk space for models (~2-4GB)</li>
                                    </ul>
                                </div>
                            </group>
                        </page>
                        <page string="Model Information">
                            <group>
                                <div>
                                    <h4>Available Models:</h4>
                                    <ul>
                                        <li><b>Qwen-2B-Small:</b> Efficient and fast, good for general queries</li>
                                        <li><b>TinyLlama:</b> Lightweight model, faster inference</li>
                                        <li><b>Custom:</b> Use any GGUF model from Hugging Face</li>
                                    </ul>
                                </div>
                            </group>
                        </page>
                    </notebook>
                </sheet>
            </form>
        </field>
    </record>

    <!-- Vanna Configuration list View -->
    <record id="view_vanna_config_list" model="ir.ui.view">
        <field name="name">vanna.config.list</field>
        <field name="model">vanna.config</field>
        <field name="arch" type="xml">
            <list string="Vanna Configurations">
                <field name="llm_backend"/>
                <field name="llm_status"/>
                <field name="llm_port"/>
                <field name="vanna_trained"/>
            </list>
        </field>
    </record>

    <!-- Action -->
    <record id="action_vanna_config" model="ir.actions.act_window">
        <field name="name">Vanna AI Configuration</field>
        <field name="res_model">vanna.config</field>
        <field name="view_mode">list,form</field>
        <field name="help" type="html">
            <p class="o_view_nocontent_smiling_face">
                Configure your Vanna AI Assistant
            </p>
            <p>
                Set up the local LLM backend and start the AI chatbot service.
            </p>
        </field>
    </record>

    <!-- Menu -->
    <menuitem id="menu_vanna_root"
              name="Vanna AI"
              sequence="100"/>

    <menuitem id="menu_vanna_config"
              name="Configuration"
              parent="menu_vanna_root"
              action="action_vanna_config"
              sequence="1"/>
</odoo>